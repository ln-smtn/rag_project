{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28491233",
   "metadata": {},
   "source": [
    "Работа с векторными базами данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fdccbc",
   "metadata": {},
   "source": [
    "1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff1da09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenasmetanina/Desktop/Sbertech/rag-project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9e7a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Структура датасета:\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['query-id', 'corpus-id', 'score'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n",
      "\n",
      "Доступные разделы: ['test']\n",
      "\n",
      "test:\n",
      "  Количество строк: 10000\n",
      "  Колонки: ['query-id', 'corpus-id', 'score']\n",
      "  Пример первой строки: {'query-id': '0', 'corpus-id': '670487', 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "dataset = load_dataset(\"ai-forever/ria-news-retrieval\")\n",
    "print(\"Структура датасета:\")\n",
    "print(dataset)\n",
    "print(\"\\nДоступные разделы:\", list(dataset.keys()))\n",
    "\n",
    "# Проверяем структуру каждого раздела\n",
    "for split_name in dataset.keys():\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(f\"  Количество строк: {len(dataset[split_name])}\")\n",
    "    print(f\"  Колонки: {dataset[split_name].column_names}\")\n",
    "    if len(dataset[split_name]) > 0:\n",
    "        print(f\"  Пример первой строки: {dataset[split_name][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1122de",
   "metadata": {},
   "source": [
    "2. Исследование структуры датасета и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151809a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Попытка загрузки queries через конфигурацию 'queries'...\n",
      "✓ Queries загружены (split='queries')\n",
      "\n",
      "Попытка загрузки corpus через конфигурацию 'corpus'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating corpus split: 100%|██████████| 704344/704344 [00:02<00:00, 269339.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Corpus загружен из конфигурации 'corpus' (split: corpus)\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ЗАГРУЗКИ\n",
      "================================================================================\n",
      "\n",
      "✓ Queries: 10000 запросов\n",
      "  Колонки: ['_id', 'text']\n",
      "  Пример: {'_id': '0', 'text': 'сми: планируется создание в рф несетевых магазинов возле жилых домов'}\n",
      "\n",
      "✓ Corpus: 704344 документов\n",
      "  Колонки: ['_id', 'title', 'text']\n",
      "  Пример текста (первые 200 символов): премьер-министр украины, кандидат в президенты юлия тимошенко в воскресенье в прямом эфире украинского телеканала 1+1 заявила, что в случае ее победы на выборах президента юрий луценко будет работать...\n",
      "\n",
      "✓ Test/Default: 10000 соответствий\n",
      "  Колонки: ['query-id', 'corpus-id', 'score']\n",
      "  Пример: {'query-id': '0', 'corpus-id': '670487', 'score': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Загружаем отдельные разделы датасета\n",
    "# Для retrieval датасетов queries и corpus могут быть отдельными конфигурациями\n",
    "queries = None\n",
    "corpus = None\n",
    "test = None\n",
    "\n",
    "# Способ 1: Пробуем загрузить queries через конфигурацию 'queries'\n",
    "try:\n",
    "    print(\"Попытка загрузки queries через конфигурацию 'queries'...\")\n",
    "    # Пробуем разные варианты split\n",
    "    try:\n",
    "        queries = load_dataset(\"ai-forever/ria-news-retrieval\", name=\"queries\", split=\"queries\")\n",
    "        print(\"✓ Queries загружены (split='queries')\")\n",
    "    except:\n",
    "        # Если split не нужен, загружаем весь датасет queries\n",
    "        queries_dataset = load_dataset(\"ai-forever/ria-news-retrieval\", name=\"queries\")\n",
    "        # Берем первый доступный split\n",
    "        if queries_dataset:\n",
    "            queries = list(queries_dataset.values())[0]\n",
    "            print(f\"✓ Queries загружены из конфигурации (split: {list(queries_dataset.keys())[0]})\")\n",
    "except Exception as e:\n",
    "    print(f\"Не удалось загрузить queries через конфигурацию: {e}\")\n",
    "\n",
    "# Способ 2: Пробуем загрузить corpus через разные конфигурации\n",
    "# Функция для проверки, что corpus содержит тексты\n",
    "def is_valid_corpus(corpus_data):\n",
    "    \"\"\"Проверяет, что corpus содержит текстовую колонку\"\"\"\n",
    "    if corpus_data is None:\n",
    "        return False\n",
    "    text_columns = ['text', 'content', 'document', 'passage', 'body', 'article']\n",
    "    return any(col in corpus_data.column_names for col in text_columns)\n",
    "\n",
    "if corpus is None:\n",
    "    # Пробуем разные варианты названий конфигураций для corpus\n",
    "    config_names_to_try = ['corpus', 'documents', 'passages', 'docs', 'collection']\n",
    "    \n",
    "    for config_name in config_names_to_try:\n",
    "        try:\n",
    "            print(f\"\\nПопытка загрузки corpus через конфигурацию '{config_name}'...\")\n",
    "            corpus_dataset = load_dataset(\"ai-forever/ria-news-retrieval\", name=config_name)\n",
    "            if corpus_dataset:\n",
    "                corpus_candidate = list(corpus_dataset.values())[0]\n",
    "                if is_valid_corpus(corpus_candidate):\n",
    "                    corpus = corpus_candidate\n",
    "                    print(f\"✓ Corpus загружен из конфигурации '{config_name}' (split: {list(corpus_dataset.keys())[0]})\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"  Конфигурация '{config_name}' не содержит текстов (колонки: {corpus_candidate.column_names})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Не удалось загрузить через '{config_name}': {e}\")\n",
    "    \n",
    "    # Если не нашли через другие конфигурации, пробуем 'default' (но проверяем, что это не test)\n",
    "    if corpus is None:\n",
    "        try:\n",
    "            print(\"\\nПопытка загрузки corpus через конфигурацию 'default'...\")\n",
    "            corpus_dataset = load_dataset(\"ai-forever/ria-news-retrieval\", name=\"default\")\n",
    "            if corpus_dataset:\n",
    "                corpus_candidate = list(corpus_dataset.values())[0]\n",
    "                if is_valid_corpus(corpus_candidate):\n",
    "                    corpus = corpus_candidate\n",
    "                    print(f\"✓ Corpus загружен из конфигурации 'default' (split: {list(corpus_dataset.keys())[0]})\")\n",
    "                else:\n",
    "                    print(f\"  Конфигурация 'default' не содержит текстов (колонки: {corpus_candidate.column_names})\")\n",
    "                    print(f\"  Это похоже на файл соответствий, а не на corpus с текстами\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось загрузить corpus через 'default': {e}\")\n",
    "\n",
    "# Способ 3: Пробуем загрузить как отдельные splits из основного датасета\n",
    "if queries is None or corpus is None:\n",
    "    try:\n",
    "        print(\"\\nПопытка загрузки queries и corpus как отдельных splits...\")\n",
    "        full_dataset = load_dataset(\"ai-forever/ria-news-retrieval\")\n",
    "        print(f\"Доступные разделы: {list(full_dataset.keys())}\")\n",
    "        \n",
    "        # Ищем queries и corpus в доступных разделах\n",
    "        for key in full_dataset.keys():\n",
    "            key_lower = key.lower()\n",
    "            if ('query' in key_lower or 'queries' in key_lower) and queries is None:\n",
    "                queries = full_dataset[key]\n",
    "                print(f\"✓ Найден queries в разделе '{key}'\")\n",
    "            elif 'corpus' in key_lower and corpus is None:\n",
    "                corpus = full_dataset[key]\n",
    "                print(f\"✓ Найден corpus в разделе '{key}'\")\n",
    "            elif ('test' in key_lower or 'default' in key_lower) and test is None:\n",
    "                test = full_dataset[key]\n",
    "                print(f\"✓ Найден test/default в разделе '{key}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке: {e}\")\n",
    "\n",
    "# Если test не загружен, используем из dataset\n",
    "if test is None:\n",
    "    test = dataset.get(\"test\", None)\n",
    "\n",
    "# Выводим информацию о загруженных данных\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РЕЗУЛЬТАТЫ ЗАГРУЗКИ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if queries is not None:\n",
    "    print(f\"\\n✓ Queries: {len(queries)} запросов\")\n",
    "    print(f\"  Колонки: {queries.column_names}\")\n",
    "    if len(queries) > 0:\n",
    "        print(f\"  Пример: {queries[0]}\")\n",
    "else:\n",
    "    print(\"\\n⚠ Queries не найдены - возможно, нужно извлечь из test\")\n",
    "\n",
    "if corpus is not None:\n",
    "    print(f\"\\n✓ Corpus: {len(corpus)} документов\")\n",
    "    print(f\"  Колонки: {corpus.column_names}\")\n",
    "    if len(corpus) > 0:\n",
    "        # Показываем пример, но проверяем наличие текстовой колонки\n",
    "        text_cols = [c for c in corpus.column_names if c in ['text', 'content', 'document', 'passage', 'body', 'article']]\n",
    "        if text_cols:\n",
    "            sample_text = corpus[0][text_cols[0]]\n",
    "            print(f\"  Пример текста (первые 200 символов): {str(sample_text)[:200]}...\")\n",
    "        else:\n",
    "            sample = str(corpus[0])\n",
    "            print(f\"  Пример записи: {sample[:200]}...\")\n",
    "            print(f\"  ⚠ ВНИМАНИЕ: Не найдена текстовая колонка! Возможно, загружен не тот corpus.\")\n",
    "else:\n",
    "    print(\"\\n⚠ Corpus не найден!\")\n",
    "    print(\"  Возможные причины:\")\n",
    "    print(\"  1. Corpus может быть в другой конфигурации\")\n",
    "    print(\"  2. Нужно проверить документацию датасета на Hugging Face\")\n",
    "    print(\"  3. Возможно, corpus нужно загрузить отдельно\")\n",
    "\n",
    "if test is not None:\n",
    "    print(f\"\\n✓ Test/Default: {len(test)} соответствий\")\n",
    "    print(f\"  Колонки: {test.column_names}\")\n",
    "    if len(test) > 0:\n",
    "        print(f\"  Пример: {test[0]}\")\n",
    "else:\n",
    "    print(\"\\n⚠ Test/Default не найден\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08f08e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительная проверка: смотрим все доступные конфигурации датасета\n",
    "if corpus is None or not is_valid_corpus(corpus):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ПОИСК ПРАВИЛЬНОЙ КОНФИГУРАЦИИ ДЛЯ CORPUS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Пробуем получить информацию о всех конфигурациях\n",
    "        from huggingface_hub import dataset_info\n",
    "        info = dataset_info(\"ai-forever/ria-news-retrieval\")\n",
    "        print(f\"\\nДоступные конфигурации в датасете:\")\n",
    "        if hasattr(info, 'configs'):\n",
    "            for config_name in info.configs.keys():\n",
    "                print(f\"  - {config_name}\")\n",
    "        else:\n",
    "            print(\"  (информация о конфигурациях недоступна)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось получить информацию о конфигурациях: {e}\")\n",
    "    \n",
    "    # Пробуем загрузить все возможные конфигурации и проверить их\n",
    "    print(\"\\nПроверяем все возможные конфигурации...\")\n",
    "    possible_configs = ['corpus', 'documents', 'passages', 'docs', 'collection', 'default', 'queries', 'test']\n",
    "    \n",
    "    for config_name in possible_configs:\n",
    "        try:\n",
    "            config_dataset = load_dataset(\"ai-forever/ria-news-retrieval\", name=config_name)\n",
    "            if config_dataset:\n",
    "                for split_name, split_data in config_dataset.items():\n",
    "                    print(f\"\\n  Конфигурация '{config_name}', split '{split_name}':\")\n",
    "                    print(f\"    Колонки: {split_data.column_names}\")\n",
    "                    print(f\"    Количество строк: {len(split_data)}\")\n",
    "                    if is_valid_corpus(split_data) and corpus is None:\n",
    "                        corpus = split_data\n",
    "                        print(f\"    ✓ Это corpus с текстами! Используем его.\")\n",
    "                        break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if corpus is None or not is_valid_corpus(corpus):\n",
    "        print(\"\\n⚠ Corpus с текстами не найден автоматически.\")\n",
    "        print(\"Рекомендации:\")\n",
    "        print(\"1. Проверьте документацию датасета: https://huggingface.co/datasets/ai-forever/ria-news-retrieval\")\n",
    "        print(\"2. Возможно, corpus нужно загрузить отдельным запросом\")\n",
    "        print(\"3. Или corpus может быть в другом формате/файле\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc209b2",
   "metadata": {},
   "source": [
    "3. Выбор модели эмбеддингов\n",
    "\n",
    "Модель преобразует текст в числовые векторы (эмбеддинги), чтобы можно было сравнивать вопросы с текстами корпуса по смыслу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052f8874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели: sentence-transformers/distiluse-base-multilingual-cased-v1\n",
      "✓ Модель загружена. Размерность эмбеддингов: 512\n"
     ]
    }
   ],
   "source": [
    "# Выбор модели эмбеддингов\n",
    "# Можно использовать разные модели для сравнения результатов\n",
    "MODEL_NAME = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "# Альтернативные модели:\n",
    "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "# MODEL_NAME = \"sentence-transformers/LaBSE\"\n",
    "\n",
    "print(f\"Загрузка модели: {MODEL_NAME}\")\n",
    "embedding_model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"✓ Модель загружена. Размерность эмбеддингов: {embedding_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0983b1",
   "metadata": {},
   "source": [
    "4. Создание векторной базы данных (FAISS)\n",
    "\n",
    "Наполняем векторную базу эмбеддингами текстов из корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9b6586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки в corpus: ['_id', 'title', 'text']\n",
      "Используем колонку 'text' для текстов корпуса\n",
      "Колонка ID корпуса: _id\n",
      "Загружено 704344 документов из корпуса\n",
      "\n",
      "Создание эмбеддингов для корпуса...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22011/22011 [48:44<00:00,  7.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Эмбеддинги созданы за 2945.89 секунд\n",
      "Размерность: (704344, 512)\n",
      "\n",
      "Создание FAISS индекса (размерность: 512)...\n",
      "✓ В векторную базу добавлено 704344 векторов\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных корпуса\n",
    "# Определяем, какая колонка содержит текст\n",
    "if corpus is None:\n",
    "    raise ValueError(\"Corpus не загружен! Проверьте структуру датасета.\")\n",
    "\n",
    "# Проверяем, что corpus содержит текстовую колонку\n",
    "print(f\"Колонки в corpus: {corpus.column_names}\")\n",
    "\n",
    "# Пробуем найти колонку с текстом\n",
    "text_column = None\n",
    "text_column_candidates = ['text', 'content', 'document', 'passage', 'body', 'article', 'sentence']\n",
    "for col in text_column_candidates:\n",
    "    if col in corpus.column_names:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    # Если не нашли стандартную колонку, ищем колонки, которые не являются ID или числовыми\n",
    "    non_id_cols = [c for c in corpus.column_names \n",
    "                   if 'id' not in c.lower() \n",
    "                   and c not in ['score', 'label', 'index']]\n",
    "    \n",
    "    if non_id_cols:\n",
    "        # Берем самую длинную колонку (вероятно, это текст)\n",
    "        text_column = non_id_cols[0]\n",
    "        print(f\"⚠ ВНИМАНИЕ: Не найдена стандартная текстовая колонка!\")\n",
    "        print(f\"⚠ Используем колонку '{text_column}' как текст\")\n",
    "        print(f\"⚠ Убедитесь, что это правильная колонка с текстами документов!\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Не найдена текстовая колонка в corpus! \"\n",
    "            f\"Доступные колонки: {corpus.column_names}. \"\n",
    "            f\"Возможно, загружен не тот corpus (например, файл соответствий вместо текстов).\"\n",
    "        )\n",
    "\n",
    "print(f\"Используем колонку '{text_column}' для текстов корпуса\")\n",
    "\n",
    "# Извлекаем тексты и создаем маппинг ID -> текст\n",
    "corpus_texts = []\n",
    "corpus_id_mapping = {}  # индекс в векторах -> corpus_id\n",
    "\n",
    "# Определяем колонку с ID корпуса\n",
    "corpus_id_column = None\n",
    "for col in ['id', 'corpus-id', 'corpus_id', '_id']:\n",
    "    if col in corpus.column_names:\n",
    "        corpus_id_column = col\n",
    "        break\n",
    "\n",
    "print(f\"Колонка ID корпуса: {corpus_id_column if corpus_id_column else 'индекс'}\")\n",
    "\n",
    "# Создаем список текстов и маппинг\n",
    "for idx, item in enumerate(corpus):\n",
    "    text = item[text_column]\n",
    "    corpus_texts.append(text)\n",
    "    corpus_id = item[corpus_id_column] if corpus_id_column else idx\n",
    "    corpus_id_mapping[idx] = corpus_id\n",
    "\n",
    "print(f\"Загружено {len(corpus_texts)} документов из корпуса\")\n",
    "\n",
    "# Создаем эмбеддинги для корпуса\n",
    "print(\"\\nСоздание эмбеддингов для корпуса...\")\n",
    "start_time = time.time()\n",
    "corpus_embeddings = embedding_model.encode(\n",
    "    corpus_texts,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "print(f\"✓ Эмбеддинги созданы за {time.time() - start_time:.2f} секунд\")\n",
    "print(f\"Размерность: {corpus_embeddings.shape}\")\n",
    "\n",
    "# Нормализуем векторы для косинусного сходства\n",
    "corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Создаем FAISS индекс\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "print(f\"\\nСоздание FAISS индекса (размерность: {dimension})...\")\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product для нормализованных векторов = косинусное сходство\n",
    "\n",
    "# Добавляем векторы в индекс\n",
    "index.add(corpus_embeddings.astype('float32'))\n",
    "print(f\"✓ В векторную базу добавлено {index.ntotal} векторов\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec23abe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка текста запросов: text\n",
      "Колонка ID запросов: _id\n",
      "Загружено 10000 запросов\n",
      "\n",
      "Колонка query_id в test: query-id\n",
      "Колонка corpus_id в test: corpus-id\n",
      "Загружено 10000 соответствий query -> corpus\n",
      "\n",
      "✓ Данные подготовлены для оценки\n"
     ]
    }
   ],
   "source": [
    "# Подготовка queries и test данных\n",
    "if queries is None:\n",
    "    raise ValueError(\"Queries не загружены!\")\n",
    "\n",
    "if test is None:\n",
    "    raise ValueError(\"Test/Default не загружен!\")\n",
    "\n",
    "# Определяем колонки\n",
    "query_text_column = None\n",
    "for col in ['text', 'query', 'content']:\n",
    "    if col in queries.column_names:\n",
    "        query_text_column = col\n",
    "        break\n",
    "if query_text_column is None:\n",
    "    query_text_column = [c for c in queries.column_names if 'id' not in c.lower()][0]\n",
    "\n",
    "query_id_column = None\n",
    "for col in ['id', 'query-id', 'query_id', '_id']:\n",
    "    if col in queries.column_names:\n",
    "        query_id_column = col\n",
    "        break\n",
    "\n",
    "print(f\"Колонка текста запросов: {query_text_column}\")\n",
    "print(f\"Колонка ID запросов: {query_id_column if query_id_column else 'индекс'}\")\n",
    "\n",
    "# Создаем словарь query_id -> текст\n",
    "query_dict = {}\n",
    "for item in queries:\n",
    "    q_id = item[query_id_column] if query_id_column else queries.index(item)\n",
    "    q_text = item[query_text_column]\n",
    "    query_dict[q_id] = q_text\n",
    "\n",
    "print(f\"Загружено {len(query_dict)} запросов\")\n",
    "\n",
    "# Создаем словарь query_id -> правильный corpus_id из test\n",
    "# Определяем колонки в test\n",
    "test_query_id_col = None\n",
    "test_corpus_id_col = None\n",
    "\n",
    "for col in ['query-id', 'query_id', 'query-id', 'query']:\n",
    "    if col in test.column_names:\n",
    "        test_query_id_col = col\n",
    "        break\n",
    "\n",
    "for col in ['corpus-id', 'corpus_id', 'corpus-id', 'corpus', 'document-id', 'document_id']:\n",
    "    if col in test.column_names:\n",
    "        test_corpus_id_col = col\n",
    "        break\n",
    "\n",
    "print(f\"\\nКолонка query_id в test: {test_query_id_col}\")\n",
    "print(f\"Колонка corpus_id в test: {test_corpus_id_col}\")\n",
    "\n",
    "# Создаем маппинг query_id -> правильный corpus_id\n",
    "ground_truth = {}\n",
    "for item in test:\n",
    "    q_id = item[test_query_id_col] if test_query_id_col else test.index(item)\n",
    "    c_id = item[test_corpus_id_col] if test_corpus_id_col else None\n",
    "    if c_id is not None:\n",
    "        ground_truth[q_id] = c_id\n",
    "\n",
    "print(f\"Загружено {len(ground_truth)} соответствий query -> corpus\")\n",
    "\n",
    "# Создаем обратный маппинг corpus_id -> индекс в векторах\n",
    "corpus_id_to_index = {corpus_id: idx for idx, corpus_id in corpus_id_mapping.items()}\n",
    "\n",
    "print(f\"\\n✓ Данные подготовлены для оценки\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010e397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095fd647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "НАЧАЛО ОЦЕНКИ КАЧЕСТВА ПОИСКА\n",
      "================================================================================\n",
      "Модель: sentence-transformers/distiluse-base-multilingual-cased-v1\n",
      "Векторная база: FAISS (IndexFlatIP)\n",
      "Количество документов в корпусе: 704344\n",
      "Количество запросов: 10000\n",
      "Количество соответствий в ground_truth: 10000\n",
      "\n",
      "Создание эмбеддингов для 10000 запросов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 313/313 [00:11<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Эмбеддинги запросов созданы\n",
      "\n",
      "Выполнение поиска для 10000 запросов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка запросов:   0%|          | 6/10000 [00:00<08:30, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query 1 (ID: 0) ---\n",
      "Текст: сми: планируется создание в рф несетевых магазинов возле жилых домов\n",
      "Правильный corpus_id: 670487\n",
      "Top-10 результаты:\n",
      "  1. ✗ ID 240745 (расстояние: 0.4320): требования к строительству жилья на дачных участках в московской области планируется ужесточить пос...\n",
      "  2. ✗ ID 240707 (расстояние: 0.4320): требования к строительству жилья на дачных участках в московской области планируется ужесточить пос...\n",
      "  3. ✗ ID 593361 (расстояние: 0.4300): почти 40 тысяч квадратных метров жилья планируется построить на месте шести пятиэтажек в районе бес...\n",
      "  4. ✗ ID 543337 (расстояние: 0.4248): жители многоэтажки на красном проспекте в новосибирске выступили против проведения строительных рабо...\n",
      "  5. ✗ ID 422846 (расстояние: 0.4233): «торговый дом перекресток» приступил к отделочным работам в зоне супермаркета торгового центра «изм...\n",
      "  6. ✗ ID 465507 (расстояние: 0.4229): каждый пятый британский магазин закроется к 2018 году в связи с ростом популярности интернет-торг...\n",
      "  7. ✗ ID 575227 (расстояние: 0.4212): жилье, предполагающее социальный найм, будет строиться, скорее всего, на новых территориях москвы,...\n",
      "  8. ✗ ID 645599 (расстояние: 0.4198): российский аукционный дом (рад) 24 сентября проведет на балтийской торговой площадке торги по ...\n",
      "  9. ✗ ID 570937 (расстояние: 0.4192): реализация программы \"жилье для российской семьи\" — одна из приоритетных задач для карачаево-черке...\n",
      "  10. ✗ ID 383058 (расстояние: 0.4177): строительство одного из двух многоквартирных домов по программе \"жилье для бюджетников\" началось нак...\n",
      "\n",
      "--- Query 2 (ID: 1) ---\n",
      "Текст: барулин сожалеет, что набокова нет на хоккейном кубке первого канала\n",
      "Правильный corpus_id: 116739\n",
      "Top-10 результаты:\n",
      "  1. ✗ ID 274764 (расстояние: 0.5975): вадим кузнецов. неудачная игра в первом периоде помешала \"ак барсу\" лучше сыграть с хоккеистами \"сев...\n",
      "  2. ✗ ID 248049 (расстояние: 0.5916): вину за неудачи \"ак барса\" на старте сезона кхл должны взять на себя хоккеисты команды, заявил форва...\n",
      "  3. ✗ ID 135042 (расстояние: 0.5897): хоккеисты \"ак барса\" не должны быть довольны своей игрой, несмотря на победу в первом матче 1/8 фи...\n",
      "  4. ✓ ID 116739 (расстояние: 0.5856): вратарь сборной россии по хоккею константин барулин выразил сожаление, что обстоятельства не позвол...\n",
      "  5. ✗ ID 151877 (расстояние: 0.5774): хоккеисты \"ак барса\" не имеют претензий к вратарю команды петри веханену, ошибка которого привела к...\n",
      "  6. ✗ ID 225612 (расстояние: 0.5768): хоккеисты \"ак барса\" могут быть довольны своей игрой в матче с рижским \"динамо\", рассказал для \"р-...\n",
      "  7. ✗ ID 677566 (расстояние: 0.5715): хоккеисты \"барыса\" играли на равных с казанским \"ак барсом\", заявил старший тренер астанинцев игорь...\n",
      "  8. ✗ ID 283931 (расстояние: 0.5650): хоккеисты \"нефтехимика\" отдали все силы в матче с \"ак барсом\", заявил журналистам главный тренер ни...\n",
      "  9. ✗ ID 660314 (расстояние: 0.5596): нападающий казанского \"ак барса\" оскар меллер не сыграет за сборную швеции по хоккею на первом этап...\n",
      "  10. ✗ ID 275601 (расстояние: 0.5586): хоккеисты чеховского \"витязя\" неожиданно рано начали устраивать драки в матче с \"ак барсом\", заявил ...\n",
      "\n",
      "--- Query 3 (ID: 2) ---\n",
      "Текст: британские куры забили насмерть лису, проникшую в курятник\n",
      "Правильный corpus_id: 26225\n",
      "Top-10 результаты:\n",
      "  1. ✓ ID 26225 (расстояние: 0.5804): семейство британских кур забило насмерть лисицу, проникшую в курятник на ферме в английском графст...\n",
      "  2. ✗ ID 354805 (расстояние: 0.4792): британская полиция пытается отыскать льва, в ночь на воскресенье бежавшего, как предполагается, из г...\n",
      "  3. ✗ ID 616779 (расстояние: 0.4725): директор британского зоопарка спас от гибели двух тигров, которых хотели усыпить, сообщает газета da...\n",
      "  4. ✗ ID 405153 (расстояние: 0.4608): британские полицейские были вызваны расследовать дело о хищении курицы бенгальским котом в графстве...\n",
      "  5. ✗ ID 453758 (расстояние: 0.4588): зоозащитники из сша считают, что отравление свинцом стало причиной гибели, по меньшей мере, трех о...\n",
      "  6. ✗ ID 354305 (расстояние: 0.4562): британская полиция во вторник прекратила поиски сбежавшего циркового льва, почти сутки державшего в ...\n",
      "  7. ✗ ID 684535 (расстояние: 0.4515): опасения британцев стали предметом для шутки российского вице-премьера дмитрия рогозина.\n",
      "  8. ✗ ID 280642 (расстояние: 0.4500): британцы хотят объявить войну 10 наиболее агрессивным чужеземным животным и растениям, которые унич...\n",
      "  9. ✗ ID 512896 (расстояние: 0.4495): два десятка кондоров, относящихся к редким видам птиц, отравились в чили, две из них погибли, сообща...\n",
      "  10. ✗ ID 646811 (расстояние: 0.4494): специалисты обнаружили в 50,5 тонны курятины, ввезенной в приморский край из великобритании, возб...\n",
      "\n",
      "--- Query 4 (ID: 3) ---\n",
      "Текст: путин: сотрудники овд получат выплаты на приобретение жилья и в 2013 г\n",
      "Правильный corpus_id: 288389\n",
      "Top-10 результаты:\n",
      "  1. ✗ ID 457879 (расстояние: 0.5311): около 100 ветеранов и вдов участников великой отечественной войны, живущих в томской области, по...\n",
      "  2. ✗ ID 512838 (расстояние: 0.5046): более 60 молодых вологодских семей получат в 2013 году субсидии на приобретение или строительство ж...\n",
      "  3. ✗ ID 383963 (расстояние: 0.4747): ветераны великой отечественной войны, проживающие в клинском районе подмосковья и нуждающиеся в ...\n",
      "  4. ✗ ID 513895 (расстояние: 0.4742): бюджетные трансферты в архангельской области, направляемые на приобретение и строительство жилья дл...\n",
      "  5. ✗ ID 420549 (расстояние: 0.4694): более миллиарда рублей выделят столичным полицейским в 2013 году на покупку квартир, сообщил глава...\n",
      "  6. ✗ ID 435170 (расстояние: 0.4661): власти чукотки выделят на приобретение жилья для детей-сирот в 2013 году 15,7 миллиона рублей, что...\n",
      "  7. ✗ ID 435163 (расстояние: 0.4661): власти чукотки выделят на приобретение жилья для детей-сирот в 2013 году 15,7 миллиона рублей, что...\n",
      "  8. ✗ ID 160778 (расстояние: 0.4658): очередь российских военнослужащих на получение жилья планируется ликвидировать к 2014 году, сообщил...\n",
      "  9. ✗ ID 584305 (расстояние: 0.4632): объемы продаж жилья группы лср в 2013 году выросли по сравнению с 2012 годом на 69% - до 753 тысяч к...\n",
      "  10. ✗ ID 577543 (расстояние: 0.4631): ввод жилья в пензенской области в 2013 году вырос по сравнению с 2012 годом на 12,07% - до 829,4 ты...\n",
      "\n",
      "--- Query 5 (ID: 4) ---\n",
      "Текст: футболист \"зенита\" данни пропустит стыковые игры за выход на евро-2012\n",
      "Правильный corpus_id: 256787\n",
      "Top-10 результаты:\n",
      "  1. ✗ ID 272254 (расстояние: 0.6799): футболисты сборной россии должны выходить в плей-офф евро-2012, поскольку будут соперничать за вых...\n",
      "  2. ✗ ID 243372 (расстояние: 0.6561): футболисты сборной россии не будут отсиживаться в обороне в выездном матче квалификации чемпионата ...\n",
      "  3. ✗ ID 244722 (расстояние: 0.6440): футболисты национальной сборной могут одержать победу над словакией, в матче отборочного раунда ч...\n",
      "  4. ✗ ID 272270 (расстояние: 0.6312): мастерство футболистов и удачный жребий позволяет надеяться на легкий выход сборной россии в пле...\n",
      "  5. ✗ ID 241481 (расстояние: 0.6292): футболистам сборной россии хочется выиграть у команды андорры в последнем матче отборочного турнира...\n",
      "  6. ✗ ID 245017 (расстояние: 0.6238): сборной россии по футболу в предстоящей игре квалификации чемпионата европы 2012 года со словаками...\n",
      "  7. ✗ ID 242235 (расстояние: 0.6175): футболисты сборной россии в воскресенье провели первую тренировку в рамках подготовки к заключитель...\n",
      "  8. ✗ ID 329590 (расстояние: 0.6154): футболисты \"зенита\", которые внесли немалый вклад в результаты команды по ходу сезона, нуждаются в ...\n",
      "  9. ✗ ID 255103 (расстояние: 0.6136): футболисты сборной россии должны обыгрывать любую команду, а потому им не стоит задумываться о том,...\n",
      "  10. ✗ ID 241080 (расстояние: 0.6111): футболисты столичного \"локомотива\" роман шишкин и денис глушаков выйдут в стартовом составе сборнои...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка запросов: 100%|██████████| 10000/10000 [03:50<00:00, 43.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_retrieval(\n",
    "    query_dict: Dict,\n",
    "    ground_truth: Dict,\n",
    "    corpus_id_to_index: Dict,\n",
    "    corpus_id_mapping: Dict,\n",
    "    corpus_texts: List[str],\n",
    "    embedding_model: SentenceTransformer,\n",
    "    index: faiss.Index,\n",
    "    k_values: List[int] = [1, 3, 5, 10],\n",
    "    verbose: bool = False,\n",
    "    log_errors: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Оценка качества поиска в векторной базе\n",
    "    \n",
    "    Args:\n",
    "        query_dict: словарь query_id -> текст запроса\n",
    "        ground_truth: словарь query_id -> правильный corpus_id\n",
    "        corpus_id_to_index: маппинг corpus_id -> индекс в векторах\n",
    "        corpus_id_mapping: маппинг индекс -> corpus_id\n",
    "        corpus_texts: список текстов корпуса\n",
    "        embedding_model: модель для создания эмбеддингов\n",
    "        index: FAISS индекс\n",
    "        k_values: список значений k для top-k оценки\n",
    "        verbose: подробное логирование\n",
    "        log_errors: логировать ошибки\n",
    "    \n",
    "    Returns:\n",
    "        словарь с метриками оценки\n",
    "    \"\"\"\n",
    "    # Статистика\n",
    "    stats = {\n",
    "        'total_queries': 0,\n",
    "        'processed_queries': 0,\n",
    "        'skipped_queries': 0,\n",
    "        'correct_by_k': {k: 0 for k in k_values},\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    # Создаем эмбеддинги для всех запросов\n",
    "    query_ids = list(query_dict.keys())\n",
    "    query_texts = [query_dict[q_id] for q_id in query_ids]\n",
    "    \n",
    "    print(f\"\\nСоздание эмбеддингов для {len(query_texts)} запросов...\")\n",
    "    query_embeddings = embedding_model.encode(\n",
    "        query_texts,\n",
    "        show_progress_bar=True,\n",
    "        batch_size=32,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    query_embeddings = query_embeddings / np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "    print(\"✓ Эмбеддинги запросов созданы\")\n",
    "    \n",
    "    # Прогон по всем запросам\n",
    "    print(f\"\\nВыполнение поиска для {len(query_ids)} запросов...\")\n",
    "    max_k = max(k_values)\n",
    "    \n",
    "    for i, (query_id, query_text, query_emb) in enumerate(tqdm(\n",
    "        zip(query_ids, query_texts, query_embeddings),\n",
    "        total=len(query_ids),\n",
    "        desc=\"Обработка запросов\"\n",
    "    )):\n",
    "        stats['total_queries'] += 1\n",
    "        \n",
    "        # Проверяем, есть ли правильный ответ для этого запроса\n",
    "        if query_id not in ground_truth:\n",
    "            stats['skipped_queries'] += 1\n",
    "            if verbose:\n",
    "                print(f\"⚠ Query {query_id}: нет правильного ответа в ground_truth, пропускаем\")\n",
    "            continue\n",
    "        \n",
    "        correct_corpus_id = ground_truth[query_id]\n",
    "        \n",
    "        # Проверяем, есть ли правильный corpus_id в нашей базе\n",
    "        if correct_corpus_id not in corpus_id_to_index:\n",
    "            stats['skipped_queries'] += 1\n",
    "            if verbose:\n",
    "                print(f\"⚠ Query {query_id}: правильный corpus_id {correct_corpus_id} не найден в базе\")\n",
    "            continue\n",
    "        \n",
    "        stats['processed_queries'] += 1\n",
    "        correct_index = corpus_id_to_index[correct_corpus_id]\n",
    "        \n",
    "        # Поиск в векторной базе\n",
    "        try:\n",
    "            query_emb_reshaped = query_emb.reshape(1, -1).astype('float32')\n",
    "            distances, indices = index.search(query_emb_reshaped, max_k)\n",
    "            \n",
    "            # Получаем corpus_id для найденных индексов\n",
    "            found_indices = indices[0]\n",
    "            found_corpus_ids = [corpus_id_mapping[idx] for idx in found_indices]\n",
    "            \n",
    "            # Проверяем для каждого k\n",
    "            for k in k_values:\n",
    "                top_k_ids = found_corpus_ids[:k]\n",
    "                if correct_corpus_id in top_k_ids:\n",
    "                    stats['correct_by_k'][k] += 1\n",
    "            \n",
    "            # Логируем ошибки, если правильный ответ не в top-3\n",
    "            if log_errors and correct_corpus_id not in found_corpus_ids[:3]:\n",
    "                error_info = {\n",
    "                    'query_id': query_id,\n",
    "                    'query_text': query_text[:200] + ('...' if len(query_text) > 200 else ''),\n",
    "                    'correct_corpus_id': correct_corpus_id,\n",
    "                    'top_3_corpus_ids': found_corpus_ids[:3],\n",
    "                    'top_3_snippets': [corpus_texts[found_indices[j]][:150] + '...' \n",
    "                                      for j in range(min(3, len(found_indices)))]\n",
    "                }\n",
    "                stats['errors'].append(error_info)\n",
    "            \n",
    "            # Подробное логирование\n",
    "            if verbose and i < 5:  # Показываем первые 5 запросов\n",
    "                print(f\"\\n--- Query {i+1} (ID: {query_id}) ---\")\n",
    "                print(f\"Текст: {query_text[:150]}{'...' if len(query_text) > 150 else ''}\")\n",
    "                print(f\"Правильный corpus_id: {correct_corpus_id}\")\n",
    "                print(f\"Top-{max_k} результаты:\")\n",
    "                for rank, (idx, c_id, dist) in enumerate(zip(found_indices, found_corpus_ids, distances[0]), 1):\n",
    "                    is_correct = \"✓\" if c_id == correct_corpus_id else \"✗\"\n",
    "                    snippet = corpus_texts[idx][:100] + ('...' if len(corpus_texts[idx]) > 100 else '')\n",
    "                    print(f\"  {rank}. {is_correct} ID {c_id} (расстояние: {dist:.4f}): {snippet}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при обработке query {query_id}: {e}\")\n",
    "            stats['errors'].append({\n",
    "                'query_id': query_id,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    if stats['processed_queries'] > 0:\n",
    "        stats['accuracy_by_k'] = {\n",
    "            k: stats['correct_by_k'][k] / stats['processed_queries'] \n",
    "            for k in k_values\n",
    "        }\n",
    "    else:\n",
    "        stats['accuracy_by_k'] = {k: 0.0 for k in k_values}\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Запускаем оценку\n",
    "print(\"=\" * 80)\n",
    "print(\"НАЧАЛО ОЦЕНКИ КАЧЕСТВА ПОИСКА\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Модель: {MODEL_NAME}\")\n",
    "print(f\"Векторная база: FAISS (IndexFlatIP)\")\n",
    "print(f\"Количество документов в корпусе: {len(corpus_texts)}\")\n",
    "print(f\"Количество запросов: {len(query_dict)}\")\n",
    "print(f\"Количество соответствий в ground_truth: {len(ground_truth)}\")\n",
    "\n",
    "evaluation_stats = evaluate_retrieval(\n",
    "    query_dict=query_dict,\n",
    "    ground_truth=ground_truth,\n",
    "    corpus_id_to_index=corpus_id_to_index,\n",
    "    corpus_id_mapping=corpus_id_mapping,\n",
    "    corpus_texts=corpus_texts,\n",
    "    embedding_model=embedding_model,\n",
    "    index=index,\n",
    "    k_values=[1, 3, 5, 10],\n",
    "    verbose=True,  # Показываем первые 5 запросов подробно\n",
    "    log_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53187ce",
   "metadata": {},
   "source": [
    "7. Вывод результатов оценки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811c8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ИТОГОВАЯ СТАТИСТИКА ОЦЕНКИ\n",
      "================================================================================\n",
      "\n",
      "Модель эмбеддингов: sentence-transformers/distiluse-base-multilingual-cased-v1\n",
      "Векторная база: FAISS (IndexFlatIP)\n",
      "\n",
      "Общая статистика:\n",
      "  Всего запросов: 10000\n",
      "  Обработано запросов: 10000\n",
      "  Пропущено запросов: 0\n",
      "\n",
      "Точность (Accuracy) по Top-K:\n",
      "  Top- 1:  3141/10000 =  31.41%\n",
      "  Top- 3:  4515/10000 =  45.15%\n",
      "  Top- 5:  5091/10000 =  50.91%\n",
      "  Top-10:  5811/10000 =  58.11%\n",
      "\n",
      "Ошибки (запросы, где правильный ответ не в Top-3): 5485\n",
      "\n",
      "Примеры ошибок (первые 5):\n",
      "\n",
      "  Ошибка 1:\n",
      "    Query ID: 0\n",
      "    Текст запроса: сми: планируется создание в рф несетевых магазинов возле жилых домов\n",
      "    Правильный corpus_id: 670487\n",
      "    Top-3 найденные corpus_id: ['240745', '240707', '593361']\n",
      "    Snippets найденных результатов:\n",
      "      1. требования к строительству жилья на дачных участках в московской области планируется ужесточить после внесения ряда поправок в федеральное законодате...\n",
      "      2. требования к строительству жилья на дачных участках в московской области планируется ужесточить после внесения ряда поправок в федеральное законодате...\n",
      "      3. почти 40 тысяч квадратных метров жилья планируется построить на месте шести пятиэтажек в районе бескудниково на севере москвы, которые будут снесены ...\n",
      "\n",
      "  Ошибка 2:\n",
      "    Query ID: 1\n",
      "    Текст запроса: барулин сожалеет, что набокова нет на хоккейном кубке первого канала\n",
      "    Правильный corpus_id: 116739\n",
      "    Top-3 найденные corpus_id: ['274764', '248049', '135042']\n",
      "    Snippets найденных результатов:\n",
      "      1. вадим кузнецов. неудачная игра в первом периоде помешала \"ак барсу\" лучше сыграть с хоккеистами \"северстали\", рассказал агентству \"р-спорт\" форвард ка...\n",
      "      2. вину за неудачи \"ак барса\" на старте сезона кхл должны взять на себя хоккеисты команды, заявил форвард казанцев олег петров. победа над магнитогорским...\n",
      "      3. хоккеисты \"ак барса\" не должны быть довольны своей игрой, несмотря на победу в первом матче 1/8 финала плей-офф чемпионата кхл над \"барысом\", счита...\n",
      "\n",
      "  Ошибка 3:\n",
      "    Query ID: 3\n",
      "    Текст запроса: путин: сотрудники овд получат выплаты на приобретение жилья и в 2013 г\n",
      "    Правильный corpus_id: 288389\n",
      "    Top-3 найденные corpus_id: ['457879', '512838', '383963']\n",
      "    Snippets найденных результатов:\n",
      "      1. около 100 ветеранов и вдов участников великой отечественной войны, живущих в томской области, получат в 2013 году выплаты на приобретение жилья, с...\n",
      "      2. более 60 молодых вологодских семей получат в 2013 году субсидии на приобретение или строительство жилья в рамках фцп \"жилище\", сообщил риа новости со...\n",
      "      3. ветераны великой отечественной войны, проживающие в клинском районе подмосковья и нуждающиеся в улучшении жилищных условий, получат по 1,6 миллио...\n",
      "\n",
      "  Ошибка 4:\n",
      "    Query ID: 4\n",
      "    Текст запроса: футболист \"зенита\" данни пропустит стыковые игры за выход на евро-2012\n",
      "    Правильный corpus_id: 256787\n",
      "    Top-3 найденные corpus_id: ['272254', '243372', '244722']\n",
      "    Snippets найденных результатов:\n",
      "      1. футболисты сборной россии должны выходить в плей-офф евро-2012, поскольку будут соперничать за выход из группы со средними командами, заявил агентст...\n",
      "      2. футболисты сборной россии не будут отсиживаться в обороне в выездном матче квалификации чемпионата европы-2012 со словакией в жилине, заявил агентст...\n",
      "      3. футболисты национальной сборной могут одержать победу над словакией, в матче отборочного раунда чемпионата европы 2012 по футболу, несмотря на то, ...\n",
      "\n",
      "  Ошибка 5:\n",
      "    Query ID: 6\n",
      "    Текст запроса: ливийские повстанцы захватили крупный город марса-эль-брега\n",
      "    Правильный corpus_id: 146316\n",
      "    Top-3 найденные corpus_id: ['155857', '154162', '213081']\n",
      "    Snippets найденных результатов:\n",
      "      1. по меньшей мере четыре человека погибли и порядка десяти получили ранения в результате авиаобстрела города марса-эль-брега на востоке ливии, сообщил ...\n",
      "      2. жители ливийского города рас-эль-ануф спешно покидают свои дома и выезжают на восток в сторону города марса-эль-брега, опасаясь атаки правительственн...\n",
      "      3. отряды противников лидера ливии муамара каддафи захватили часть жилых кварталов на востоке и юге важного нефтяного порта марса-эль-брега, сообщает в ч...\n",
      "\n",
      "✓ Результаты сохранены в переменную 'results_summary'\n",
      "  Для сохранения в файл используйте: json.dump(results_summary, open('results.json', 'w'), indent=2)\n"
     ]
    }
   ],
   "source": [
    "# Вывод итоговой статистики\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ИТОГОВАЯ СТАТИСТИКА ОЦЕНКИ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nМодель эмбеддингов: {MODEL_NAME}\")\n",
    "print(f\"Векторная база: FAISS (IndexFlatIP)\")\n",
    "print(f\"\\nОбщая статистика:\")\n",
    "print(f\"  Всего запросов: {evaluation_stats['total_queries']}\")\n",
    "print(f\"  Обработано запросов: {evaluation_stats['processed_queries']}\")\n",
    "print(f\"  Пропущено запросов: {evaluation_stats['skipped_queries']}\")\n",
    "\n",
    "print(f\"\\nТочность (Accuracy) по Top-K:\")\n",
    "for k in sorted(evaluation_stats['accuracy_by_k'].keys()):\n",
    "    correct = evaluation_stats['correct_by_k'][k]\n",
    "    total = evaluation_stats['processed_queries']\n",
    "    accuracy = evaluation_stats['accuracy_by_k'][k]\n",
    "    print(f\"  Top-{k:2d}: {correct:5d}/{total:5d} = {accuracy*100:6.2f}%\")\n",
    "\n",
    "print(f\"\\nОшибки (запросы, где правильный ответ не в Top-3): {len(evaluation_stats['errors'])}\")\n",
    "\n",
    "# Показываем примеры ошибок\n",
    "if evaluation_stats['errors']:\n",
    "    print(f\"\\nПримеры ошибок (первые 5):\")\n",
    "    for i, error in enumerate(evaluation_stats['errors'][:5], 1):\n",
    "        print(f\"\\n  Ошибка {i}:\")\n",
    "        print(f\"    Query ID: {error.get('query_id', 'N/A')}\")\n",
    "        print(f\"    Текст запроса: {error.get('query_text', 'N/A')}\")\n",
    "        print(f\"    Правильный corpus_id: {error.get('correct_corpus_id', 'N/A')}\")\n",
    "        print(f\"    Top-3 найденные corpus_id: {error.get('top_3_corpus_ids', [])}\")\n",
    "        if 'top_3_snippets' in error:\n",
    "            print(f\"    Snippets найденных результатов:\")\n",
    "            for j, snippet in enumerate(error['top_3_snippets'], 1):\n",
    "                print(f\"      {j}. {snippet}\")\n",
    "\n",
    "# Сохраняем результаты в JSON\n",
    "results_summary = {\n",
    "    'model': MODEL_NAME,\n",
    "    'vector_store': 'FAISS (IndexFlatIP)',\n",
    "    'corpus_size': len(corpus_texts),\n",
    "    'total_queries': evaluation_stats['total_queries'],\n",
    "    'processed_queries': evaluation_stats['processed_queries'],\n",
    "    'accuracy': evaluation_stats['accuracy_by_k'],\n",
    "    'num_errors': len(evaluation_stats['errors'])\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Результаты сохранены в переменную 'results_summary'\")\n",
    "print(f\"  Для сохранения в файл используйте: json.dump(results_summary, open('results.json', 'w'), indent=2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c98eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results_summary, open('results.json', 'w'), indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a342c4",
   "metadata": {},
   "source": [
    "8. Эксперименты с разными моделями и параметрами\n",
    "\n",
    "Можно попробовать разные модели эмбеддингов и сравнить результаты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b56757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Тестирование модели: sentence-transformers/distiluse-base-multilingual-cased-v1\n",
      "================================================================================\n",
      "Загрузка модели...\n",
      "Создание эмбеддингов корпуса...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  12%|█▏        | 2618/22011 [05:58<44:17,  7.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Раскомментируйте для сравнения разных моделей:\u001b[39;00m\n\u001b[32m     72\u001b[39m alternative_models = [\n\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msentence-transformers/distiluse-base-multilingual-cased-v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33msentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33msentence-transformers/LaBSE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m  ]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m comparison_results = \u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43malternative_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m     \u001b[49m\u001b[43mquery_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m     \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcorpus_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcorpus_id_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_id_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcorpus_id_to_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_id_to_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m     \u001b[49m\u001b[43mk_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Если вы уже ранее запускали сравнение моделей и получили переменную comparison_results,\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# то вот код для вывода сравнительной таблицы отдельно.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mcompare_models\u001b[39m\u001b[34m(model_names, query_dict, ground_truth, corpus_texts, corpus_id_mapping, corpus_id_to_index, k_values)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Создаем эмбеддинги корпуса\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mСоздание эмбеддингов корпуса...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m corpus_emb = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m corpus_emb = corpus_emb / np.linalg.norm(corpus_emb, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Создаем индекс\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Sbertech/rag-project/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Sbertech/rag-project/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1130\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[32m   1129\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m                 embeddings = \u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m         all_embeddings.extend(embeddings)\n\u001b[32m   1134\u001b[39m all_embeddings = [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np.argsort(length_sorted_idx)]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Функция для быстрого сравнения разных моделей\n",
    "def compare_models(\n",
    "    model_names: List[str],\n",
    "    query_dict: Dict,\n",
    "    ground_truth: Dict,\n",
    "    corpus_texts: List[str],\n",
    "    corpus_id_mapping: Dict,\n",
    "    corpus_id_to_index: Dict,\n",
    "    k_values: List[int] = [1, 3]\n",
    "):\n",
    "    \"\"\"\n",
    "    Сравнение разных моделей эмбеддингов\n",
    "    \"\"\"\n",
    "    results_comparison = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Тестирование модели: {model_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Загружаем модель\n",
    "        print(f\"Загрузка модели...\")\n",
    "        model = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Создаем эмбеддинги корпуса\n",
    "        print(f\"Создание эмбеддингов корпуса...\")\n",
    "        corpus_emb = model.encode(corpus_texts, show_progress_bar=True, batch_size=32, convert_to_numpy=True)\n",
    "        corpus_emb = corpus_emb / np.linalg.norm(corpus_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        # Создаем индекс\n",
    "        dimension = corpus_emb.shape[1]\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        index.add(corpus_emb.astype('float32'))\n",
    "        \n",
    "        # Оцениваем\n",
    "        stats = evaluate_retrieval(\n",
    "            query_dict=query_dict,\n",
    "            ground_truth=ground_truth,\n",
    "            corpus_id_to_index=corpus_id_to_index,\n",
    "            corpus_id_mapping=corpus_id_mapping,\n",
    "            corpus_texts=corpus_texts,\n",
    "            embedding_model=model,\n",
    "            index=index,\n",
    "            k_values=k_values,\n",
    "            verbose=False,\n",
    "            log_errors=False\n",
    "        )\n",
    "        \n",
    "        results_comparison[model_name] = {\n",
    "            'accuracy': stats['accuracy_by_k'],\n",
    "            'processed': stats['processed_queries']\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nРезультаты для {model_name}:\")\n",
    "        for k in k_values:\n",
    "            print(f\"  Top-{k}: {stats['accuracy_by_k'][k]*100:.2f}%\")\n",
    "    \n",
    "    # Сравнительная таблица\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"СРАВНИТЕЛЬНАЯ ТАБЛИЦА\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Модель':<60} {'Top-1':<10} {'Top-3':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    for model_name, results in results_comparison.items():\n",
    "        top1 = results['accuracy'].get(1, 0) * 100\n",
    "        top3 = results['accuracy'].get(3, 0) * 100\n",
    "        print(f\"{model_name:<60} {top1:>6.2f}%   {top3:>6.2f}%\")\n",
    "    \n",
    "    return results_comparison\n",
    "\n",
    "# Раскомментируйте для сравнения разных моделей:\n",
    "alternative_models = [\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "     \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "     \"sentence-transformers/LaBSE\"\n",
    " ]\n",
    "comparison_results = compare_models(\n",
    "     model_names=alternative_models,\n",
    "     query_dict=query_dict,\n",
    "     ground_truth=ground_truth,\n",
    "     corpus_texts=corpus_texts,\n",
    "     corpus_id_mapping=corpus_id_mapping,\n",
    "     corpus_id_to_index=corpus_id_to_index,\n",
    "     k_values=[1, 3, 5]\n",
    " )\n",
    "# Если вы уже ранее запускали сравнение моделей и получили переменную comparison_results,\n",
    "# то вот код для вывода сравнительной таблицы отдельно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad43bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
