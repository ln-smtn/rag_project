{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28491233",
   "metadata": {},
   "source": [
    "Работа с векторными базами данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fdccbc",
   "metadata": {},
   "source": [
    "1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff1da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer #модель эмбеддингов\n",
    "from langchain_core.vectorstores import InMemoryVectorStore # библиотека векторог поиска\n",
    "from langchain_core.documents import Document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9e7a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['query-id', 'corpus-id', 'score'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ai-forever/ria-news-retrieval\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1122de",
   "metadata": {},
   "source": [
    "2. Выбор модели эмбенддингов\n",
    "\n",
    "Модель преобразует текст в числовые векторы (эмбеддинги), чтобы можно было сравнивать вопросы с текстами корпуса по смыслу.\n",
    "\n",
    "Результат:\n",
    "Готовая модель для создания векторных представлений текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc209b2",
   "metadata": {},
   "source": [
    "3. Создание векторной базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052f8874",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m vector_store = InMemoryVectorStore(embedding_model)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Преобразуем корпус в объекты Document с метаданными (id) и добавляем в векторную базу\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m corpus_texts = [x[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorpus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[32m      6\u001b[39m docs = [Document(page_content=text, metadata={\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: i}) \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(corpus_texts)]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mДобавляем \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m документов в векторное хранилище...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Sbertech/rag-project/.venv/lib/python3.12/site-packages/datasets/dataset_dict.py:87\u001b[39m, in \u001b[36mDatasetDict.__getitem__\u001b[39m\u001b[34m(self, k)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) -> Dataset:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, (\u001b[38;5;28mstr\u001b[39m, NamedSplit)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     89\u001b[39m         available_suggested_splits = [\n\u001b[32m     90\u001b[39m             split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split.TRAIN, Split.TEST, Split.VALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m     91\u001b[39m         ]\n",
      "\u001b[31mKeyError\u001b[39m: 'corpus'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Создание векторного хранилища InMemoryVectorStore с указанием модели эмбеддингов\n",
    "vector_store = InMemoryVectorStore(embedding_model)\n",
    "\n",
    "# Преобразуем корпус в объекты Document с метаданными (id) и добавляем в векторную базу\n",
    "corpus_texts = [x[\"text\"] for x in dataset[\"corpus\"]]\n",
    "docs = [Document(page_content=text, metadata={\"id\": i}) for i, text in enumerate(corpus_texts)]\n",
    "print(f\"Добавляем {len(docs)} документов в векторное хранилище...\")\n",
    "vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0983b1",
   "metadata": {},
   "source": [
    "4. Проверка поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = dataset[\"queries\"][0][\"text\"]\n",
    "results = vector_store.similarity_search(query_text, k=3)  # top-3 похожих\n",
    "print(results) #список из 3-х текстов, наиболее похожих на запрос\n",
    "#оценка качесва с default\n",
    "correct_id = dataset[\"default\"][0][\"corpus_id\"]\n",
    "top_result_ids = [r.metadata['id'] for r in results]\n",
    "\n",
    "# Проверяем, есть ли правильный ответ в top-1, top-3\n",
    "top1_correct = correct_id == top_result_ids[0]\n",
    "top3_correct = correct_id in top_result_ids\n",
    "print(f\"Top-1 correct: {top1_correct}, Top-3 correct: {top3_correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка переменных для подсчета ошибок\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "total_queries = len(dataset[\"queries\"])\n",
    "errors = []  # сюда будем добавлять неудачные запросы\n",
    "\n",
    "# Прогон по всем вопросам\n",
    "for i, query in enumerate(dataset[\"queries\"]):\n",
    "    query_text = query[\"text\"]\n",
    "    correct_id = dataset[\"default\"][i][\"corpus_id\"]\n",
    "\n",
    "    # Поиск top-3\n",
    "    results = vector_store.similarity_search(query_text, k=3)\n",
    "\n",
    "    # Логирование top-3 результатов с текстом\n",
    "    top3_texts = [r.page_content[:100] + (\"...\" if len(r.page_content) > 100 else \"\") for r in results]\n",
    "    top_result_ids = [r.metadata['id'] for r in results]\n",
    "\n",
    "    # Проверка\n",
    "    top1_correct = correct_id == top_result_ids[0]\n",
    "    top3_correct = correct_id in top_result_ids\n",
    "\n",
    "    if top1_correct:\n",
    "        correct_top1 += 1\n",
    "    if top3_correct:\n",
    "        correct_top3 += 1\n",
    "    else:\n",
    "        errors.append({\n",
    "            \"query_index\": i,\n",
    "            \"query_text\": query_text,\n",
    "            \"correct_id\": correct_id,\n",
    "            \"top_results\": top3_texts\n",
    "        })\n",
    "\n",
    "    # Красивое логирование\n",
    "    print(f\"--- Query {i} ---\")\n",
    "    print(f\"Text: {query_text[:150]}{'...' if len(query_text) > 150 else ''}\")\n",
    "    print(f\"Correct corpus ID: {correct_id}\")\n",
    "    print(\"Top-3 results:\")\n",
    "    for rank, (doc_id, snippet) in enumerate(zip(top_result_ids, top3_texts), 1):\n",
    "        print(f\"  {rank}. ID {doc_id}: {snippet}\")\n",
    "    print(f\"Top-1 correct: {top1_correct}, Top-3 correct: {top3_correct}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Итоговая статистика\n",
    "print(\"\\n=== Итоговая статистика ===\")\n",
    "print(f\"Всего запросов: {total_queries}\")\n",
    "print(f\"Top-1 accuracy: {correct_top1}/{total_queries} = {correct_top1 / total_queries:.2%}\")\n",
    "print(f\"Top-3 accuracy: {correct_top3}/{total_queries} = {correct_top3 / total_queries:.2%}\")\n",
    "print(f\"Ошибки: {len(errors)}\")\n",
    "\n",
    "# Пример ошибок (первые 3)\n",
    "if errors:\n",
    "    print(\"\\nПримеры ошибок:\")\n",
    "    for e in errors[:3]:\n",
    "        print(f\"\\nQuery {e['query_index']}: {e['query_text'][:150]}...\")\n",
    "        print(f\"Correct ID: {e['correct_id']}\")\n",
    "        print(\"Top-3 results (snippets):\")\n",
    "        for snippet in e['top_results']:\n",
    "            print(f\"  - {snippet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad43bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
